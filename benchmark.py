import time
import psutil
import os
import pandas as pd
from datetime import datetime


# ========= Syst√®me de Benchmark et Comparaison =========
#
# Mesure temps d'ex√©cution, CPU, m√©moire pour les algorithmes TSP
# Enregistre les r√©sultats dans un CSV pour analyse
#
# ========================================================


def measure_performance(algorithm_func, data, algo_name, **kwargs):
    """
    Mesure les performances d'un algorithme TSP.

    Args:
        algorithm_func: Fonction de l'algorithme √† tester (cristo_complete ou genetic_tsp)
        data: DataFrame des villes
        algo_name: Nom de l'algorithme pour l'affichage
        **kwargs: Param√®tres sp√©cifiques √† l'algorithme

    Returns:
        Dictionnaire avec les m√©triques de performance et le r√©sultat
    """
    # --- R√©cup√©ration du processus actuel ---
    process = psutil.Process(os.getpid())

    # --- M√©moire avant ---
    mem_before = process.memory_info().rss / (1024 * 1024)  # en MB

    # --- CPU avant ---
    cpu_percent_before = process.cpu_percent(interval=0.1)

    # --- Temps d'ex√©cution ---
    start_time = time.time()

    # Ex√©cution de l'algorithme
    result = algorithm_func(data, **kwargs)

    end_time = time.time()
    execution_time = end_time - start_time

    # --- CPU apr√®s ---
    cpu_percent_after = process.cpu_percent(interval=0.1)
    cpu_usage = (cpu_percent_before + cpu_percent_after) / 2

    # --- M√©moire apr√®s ---
    mem_after = process.memory_info().rss / (1024 * 1024)  # en MB
    mem_used = mem_after - mem_before

    # --- Extraction des r√©sultats ---
    if "best_tour" in result:  # G√©n√©tique
        tour = result["best_tour"]
        distance = result["best_distance"]
    else:  # Christofides
        tour = result["tour"]
        distance = result["distance"]

    # --- M√©triques ---
    metrics = {
        "algorithm": algo_name,
        "distance_km": round(distance, 2),
        "execution_time_s": round(execution_time, 4),
        "cpu_percent": round(cpu_usage, 2),
        "memory_mb": round(mem_used, 2),
        "memory_total_mb": round(mem_after, 2),
        "tour": tour,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }

    # Ajouter les param√®tres sp√©cifiques
    metrics.update(kwargs)

    return metrics, result


def compare_algorithms(data, genetic_params_list, save_to_csv=True, csv_filename="results/benchmark_results.csv"):
    """
    Compare Christofides avec plusieurs configurations de l'algorithme g√©n√©tique.

    Args:
        data: DataFrame des villes
        genetic_params_list: Liste de dictionnaires de param√®tres pour l'algorithme g√©n√©tique
                            Ex: [{"pop_size": 50, "generations": 100}, {"pop_size": 100, "generations": 200}]
        save_to_csv: Sauvegarder les r√©sultats dans un CSV
        csv_filename: Nom du fichier CSV

    Returns:
        DataFrame avec tous les r√©sultats
    """
    from utils import cristo_complete
    from genetique import genetic_tsp

    print("\n" + "="*70)
    print("COMPARAISON DES ALGORITHMES TSP")
    print("="*70)

    results = []

    # --- Test Christofides ---
    print("\n[1/X] Ex√©cution de Christofides...")
    metrics_cristo, result_cristo = measure_performance(
        cristo_complete,
        data,
        "Christofides",
        verbose=False
    )

    print(f"  ‚úì Distance: {metrics_cristo['distance_km']} km")
    print(f"  ‚úì Temps: {metrics_cristo['execution_time_s']} s")
    print(f"  ‚úì CPU: {metrics_cristo['cpu_percent']}%")
    print(f"  ‚úì M√©moire: {metrics_cristo['memory_mb']} MB")

    results.append(metrics_cristo)

    # --- Test Algorithme G√©n√©tique avec diff√©rents param√®tres ---
    for i, params in enumerate(genetic_params_list, start=2):
        print(f"\n[{i}/{len(genetic_params_list)+1}] Ex√©cution G√©n√©tique - {params}...")

        metrics_genetic, result_genetic = measure_performance(
            genetic_tsp,
            data,
            f"Genetique",
            verbose=False,
            **params
        )

        print(f"  ‚úì Distance: {metrics_genetic['distance_km']} km")
        print(f"  ‚úì Temps: {metrics_genetic['execution_time_s']} s")
        print(f"  ‚úì CPU: {metrics_genetic['cpu_percent']}%")
        print(f"  ‚úì M√©moire: {metrics_genetic['memory_mb']} MB")

        results.append(metrics_genetic)

    # --- Cr√©er DataFrame ---
    df_results = pd.DataFrame(results)

    # R√©organiser les colonnes
    cols_order = ["algorithm", "distance_km", "execution_time_s", "cpu_percent", "memory_mb"]
    param_cols = [col for col in df_results.columns if col not in cols_order + ["tour", "timestamp", "memory_total_mb"]]
    cols_order.extend(param_cols)
    cols_order.extend(["memory_total_mb", "timestamp"])

    df_results = df_results[cols_order]

    # --- Sauvegarder dans CSV ---
    if save_to_csv:
        # Cr√©er le dossier results s'il n'existe pas
        os.makedirs(os.path.dirname(csv_filename), exist_ok=True)

        # Sauvegarder
        df_results.to_csv(csv_filename, index=False, encoding='utf-8')
        print(f"\n‚úì R√©sultats sauvegard√©s dans {csv_filename}")

    # --- Afficher le tableau r√©capitulatif ---
    print("\n" + "="*70)
    print("TABLEAU R√âCAPITULATIF")
    print("="*70)
    print(df_results[["algorithm", "distance_km", "execution_time_s", "cpu_percent", "memory_mb"]].to_string(index=False))

    # --- Analyse comparative ---
    print("\n" + "="*70)
    print("ANALYSE COMPARATIVE")
    print("="*70)

    best_distance_idx = df_results["distance_km"].idxmin()
    fastest_idx = df_results["execution_time_s"].idxmin()
    lowest_memory_idx = df_results["memory_mb"].idxmin()

    print(f"\nüèÜ Meilleure distance: {df_results.loc[best_distance_idx, 'algorithm']} - {df_results.loc[best_distance_idx, 'distance_km']} km")
    print(f"‚ö° Plus rapide: {df_results.loc[fastest_idx, 'algorithm']} - {df_results.loc[fastest_idx, 'execution_time_s']} s")
    print(f"üíæ Moins de m√©moire: {df_results.loc[lowest_memory_idx, 'algorithm']} - {df_results.loc[lowest_memory_idx, 'memory_mb']} MB")

    # Ratio de performance
    cristo_dist = df_results[df_results["algorithm"] == "Christofides"]["distance_km"].values[0]
    for idx, row in df_results[df_results["algorithm"] == "Genetique"].iterrows():
        ratio = ((row["distance_km"] - cristo_dist) / cristo_dist) * 100
        print(f"\nG√©n√©tique (gen={row.get('generations', 'N/A')}, pop={row.get('pop_size', 'N/A')}): {ratio:+.2f}% vs Christofides")

    print("\n" + "="*70)

    return df_results


def load_benchmark_history(csv_filename="results/benchmark_results.csv"):
    """
    Charge l'historique des benchmarks depuis un CSV.

    Args:
        csv_filename: Nom du fichier CSV

    Returns:
        DataFrame avec l'historique
    """
    if os.path.exists(csv_filename):
        return pd.read_csv(csv_filename)
    else:
        print(f"Fichier {csv_filename} introuvable.")
        return None


def append_to_benchmark_history(new_results, csv_filename="results/benchmark_results.csv"):
    """
    Ajoute de nouveaux r√©sultats √† l'historique existant.

    Args:
        new_results: DataFrame des nouveaux r√©sultats
        csv_filename: Nom du fichier CSV
    """
    if os.path.exists(csv_filename):
        history = pd.read_csv(csv_filename)
        combined = pd.concat([history, new_results], ignore_index=True)
        combined.to_csv(csv_filename, index=False, encoding='utf-8')
        print(f"‚úì R√©sultats ajout√©s √† {csv_filename}")
    else:
        new_results.to_csv(csv_filename, index=False, encoding='utf-8')
        print(f"‚úì Nouveau fichier cr√©√© : {csv_filename}")
